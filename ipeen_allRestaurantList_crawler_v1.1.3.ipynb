{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json \n",
    "from queue import Queue\n",
    "import threading\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pageUrl_pattern = '(http(s)?://)(www\\.ipeen.com.tw/search/taiwan/000/1-0-0-0/\\?p=)(\\d+)'\n",
    "def all_restaurant_list(page_url):\n",
    "    print(page_url)\n",
    "    if re.match(pageUrl_pattern, page_url) == None:        \n",
    "        print('pageURL is not found')\n",
    "    else:        \n",
    "        res = r.get(page_url)\n",
    "        res.encoding=\"utf-8\"\n",
    "        soup = bs(res.text, 'lxml')\n",
    "\n",
    "        #因為要同時寫入4個檔案，沒辦法在單一區塊中完成讀寫，所以不使用with open的原因顯而易見。\n",
    "        #當然，更不能在迴圈裡使用with open，Connection是重量級資源，反覆開關會大幅度的拖慢速度。\n",
    "        f1 = open('all_restaurant_list_block1.txt', 'a+',encoding='utf8')\n",
    "        f2 = open('all_restaurant_list_block2.txt', 'a+',encoding='utf8')\n",
    "        f3 = open('all_restaurant_list_block3.txt', 'a+',encoding='utf8')\n",
    "        f4 = open('all_restaurant_list_block4.txt', 'a+',encoding='utf8')\n",
    "\n",
    "        #為了能夠平均每個block的餐廳數量，用來分割檔案的計數使用random來初始化\n",
    "        #不直接在迴圈裡使用random是因為雖然這樣能更均衡的分配資料，但Python的偽亂數產生器使用Mersenne Twister演算法\n",
    "        #產生出來的亂數雖然品質很好，但相對也使用較多的資源。考慮到愛評網的餐廳數量，應該用更節省效能的方式來達成類似的工作。\n",
    "        initialization_count_number = random.randint(1,4)\n",
    "        count_number = initialization_count_number\n",
    "\n",
    "        #過濾掉已搬遷、已歇業的店家，取得單一餐廳的餐廳頁面url\n",
    "        #這種店家都有<span>標籤\n",
    "        #1.<span class=\"status\">【已搬遷】</span> 2.<span class=\"status\">【已歇業】</span>\n",
    "        HOST = 'http://www.ipeen.com.tw'\n",
    "        all_restaurant_in_h3_list = soup.findAll('h3', {'id':re.compile('shop_h3_\\d\\d?')})\n",
    "        try: \n",
    "            for restaurant in all_restaurant_in_h3_list:\n",
    "                if not restaurant.span:\n",
    "                    if count_number%4==1:\n",
    "                        f1.write(HOST + restaurant.a['href']+'\\n')\n",
    "                    elif count_number%4==2:\n",
    "                        f2.write(HOST + restaurant.a['href']+'\\n')\n",
    "                    elif count_number%4==3:        \n",
    "                        f3.write(HOST + restaurant.a['href']+'\\n')\n",
    "                    else:     \n",
    "                        f4.write(HOST + restaurant.a['href']+'\\n')\n",
    "        #except:\n",
    "        #    print('[ERROR]IOexception!')\n",
    "        finally:\n",
    "            f1.close()\n",
    "            f2.close()\n",
    "            f3.close()\n",
    "            f4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AWSTimeLimitError(Exception):\n",
    "    def __init__(self,msg):\n",
    "        self.message=msg\n",
    "   \n",
    "    def __str__(self):\n",
    "        return self.message\n",
    "\n",
    "def getExecutionTime(startTime):\n",
    "    if (time.time() - startTime < 600):\n",
    "        pass\n",
    "    else:\n",
    "        raise AWSTimeLimitError('Time is running out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_AllPagesListSplitBlock_function(q,startTime):\n",
    "    rf = open('all_pages_list_block1.txt', 'r',encoding='utf8')\n",
    "    pages_str = rf.read()\n",
    "    if (pages_str==''):\n",
    "        print('no url!')\n",
    "        rf.close()\n",
    "        with open('success_all_pages_list_block1.txt', 'w', encoding='utf8') as wsf:\n",
    "            wsf.write('success')\n",
    "        os.remove('all_pages_list_block1.txt')\n",
    "    else:\n",
    "        pages_list = pages_str.split('\\n')\n",
    "        for pages in range(len(pages_list)):\n",
    "            q.put(pages_list.pop())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no url!\n",
      "good\n",
      "[INFO]TotalExecutionTime = 0.004000186920166016\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':   \n",
    "    \n",
    "    startTime = time.time()  \n",
    "    \n",
    "    q = Queue()\n",
    "    t1 = threading.Thread(target=reduce_AllPagesListSplitBlock_function, args=(q,startTime,)) \n",
    "    \n",
    "    t1.start()  #啟動 t1 線程\n",
    "\n",
    "    t1.join()  #在 t1線程結束前阻止程式繼續運行\n",
    "\n",
    "    #確認Queue是否為空，如果不是就用 q.get() 取出值\n",
    "    \n",
    "    while not q.empty():\n",
    "        try:\n",
    "            getExecutionTime(startTime)\n",
    "            all_restaurant_list(q.get())\n",
    "        except AWSTimeLimitError:\n",
    "            with open('all_pages_list_block1.txt', 'w', encoding='utf8') as wf:\n",
    "                while not q.empty():\n",
    "                    page = q.get()\n",
    "                    wf.write(page + '\\n')\n",
    "    endTime = time.time() \n",
    "    totalExecutionTime = str(endTime-startTime)\n",
    "    print('good')\n",
    "    print('[INFO]TotalExecutionTime = ' + totalExecutionTime)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
